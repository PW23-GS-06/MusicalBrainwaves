{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vrOuKO1pNxFXLc2UkfDCydE2Du_zHBpl","timestamp":1692697459950}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPHhq1DKaqzG","executionInfo":{"status":"ok","timestamp":1694156848354,"user_tz":-330,"elapsed":4225,"user":{"displayName":"JEFFREY S VARGHESE 2572 Batch,PES University","userId":"11726951605376021785"}},"outputId":"eb0683e6-7c76-4138-eeab-3d583eac5520"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["PNUM = \"14\""],"metadata":{"id":"Sa-79Ao-0nqh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vllai.py\n"],"metadata":{"id":"5JyC6Ng2a7OS"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","def extractor(\n","    filters=(256, 256, 256, 128, 128),\n","    kernels=(8,) * 5,\n","    input_channels=64,\n","    normalization_fn=lambda x: tf.keras.layers.LayerNormalization()(x),\n","    activation_fn=lambda x: tf.keras.layers.LeakyReLU()(x),\n","    name=\"extractor\",\n","):\n","    \"\"\"Construct the extractor model.\n","\n","    Parameters\n","    ----------\n","    filters: Sequence[int]\n","        Number of filters for each layer.\n","    kernels: Sequence[int]\n","        Kernel size for each layer.\n","    input_channels: int\n","        Number of EEG channels in the input\n","    normalization_fn: Callable[[tf.Tensor], tf.Tensor]\n","        Function to normalize the contents of a tensor.\n","    activation_fn: Callable[[tf.Tensor], tf.Tensor]\n","        Function to apply an activation function to the contents of a tensor.\n","    name: str\n","        Name of the model.\n","\n","    Returns\n","    -------\n","    tf.keras.models.Model\n","        The extractor model.\n","    \"\"\"\n","    eeg = tf.keras.layers.Input((None, input_channels))\n","\n","    x = eeg\n","\n","    if len(filters) != len(kernels):\n","        raise ValueError(\"'filters' and 'kernels' must have the same length\")\n","\n","    # Add the convolutional layers\n","    for filter_, kernel in zip(filters, kernels):\n","        x = tf.keras.layers.Conv1D(filter_, kernel)(x)\n","        x = normalization_fn(x)\n","        x = activation_fn(x)\n","        x = tf.keras.layers.ZeroPadding1D((0, kernel - 1))(x)\n","\n","    return tf.keras.models.Model(inputs=[eeg], outputs=[x], name=name)\n","\n","\n","def output_context(\n","    filter_=64,\n","    kernel=32,\n","    input_channels=64,\n","    normalization_fn=lambda x: tf.keras.layers.LayerNormalization()(x),\n","    activation_fn=lambda x: tf.keras.layers.LeakyReLU()(x),\n","    name=\"output_context_model\",\n","):\n","    \"\"\"Construct the output context model.\n","\n","    Parameters\n","    ----------\n","    filter_: int\n","        Number of filters for the convolutional layer.\n","    kernel: int\n","        Kernel size for the convolutional layer.\n","    input_channels: int\n","        Number of EEG channels in the input.\n","    normalization_fn: Callable[[tf.Tensor], tf.Tensor]\n","        Function to normalize the contents of a tensor.\n","    activation_fn: Callable[[tf.Tensor], tf.Tensor]\n","        Function to apply an activation function to the contents of a tensor.\n","    name: str\n","        Name of the model.\n","\n","    Returns\n","    -------\n","    tf.keras.models.Model\n","        The output context model.\n","    \"\"\"\n","    inp = tf.keras.layers.Input((None, input_channels))\n","    x = tf.keras.layers.ZeroPadding1D((kernel - 1, 0))(inp)\n","    x = tf.keras.layers.Conv1D(filter_, kernel)(x)\n","    x = normalization_fn(x)\n","    x = activation_fn(x)\n","    return tf.keras.models.Model(inputs=[inp], outputs=[x], name=name)\n","\n","\n","def vlaai(\n","    nb_blocks=4,\n","    extractor_model=None,\n","    output_context_model=None,\n","    use_skip=True,\n","    input_channels=64,\n","    output_dim=1,\n","    name=\"vlaai\",\n","):\n","    \"\"\"Construct the VLAAI model.\n","\n","    Parameters\n","    ----------\n","    nb_blocks: int\n","        Number of repeated blocks to use.\n","    extractor_model: Callable[[tf.Tensor], tf.Tensor]\n","        The extractor model to use.\n","    output_context_model: Callable[[tf.Tensor], tf.Tensor]\n","        The output context model to use.\n","    use_skip: bool\n","        Whether to use skip connections.\n","    input_channels: int\n","        Number of EEG channels in the input.\n","    output_dim: int\n","        Number of output dimensions.\n","    name: str\n","        Name of the model.\n","\n","    Returns\n","    -------\n","    tf.keras.models.Model\n","        The VLAAI model.\n","    \"\"\"\n","    if extractor_model is None:\n","        extractor_model = extractor()\n","    if output_context_model is None:\n","        output_context_model = output_context()\n","\n","    eeg = tf.keras.layers.Input((None, input_channels))\n","\n","    # If using skip connections: start with x set to zero\n","    if use_skip:\n","        x = tf.zeros_like(eeg)\n","    else:\n","        x = eeg\n","\n","    # Iterate over the blocks\n","    for i in range(nb_blocks):\n","        if use_skip:\n","            x = extractor_model(eeg + x)\n","        else:\n","            x = extractor_model(x)\n","        x = tf.keras.layers.Dense(input_channels)(x)\n","        x = output_context_model(x)\n","\n","    x = tf.keras.layers.Dense(output_dim)(x)\n","\n","    return tf.keras.models.Model(inputs=[eeg], outputs=[x], name=name)\n","\n","def pearson_tf(y_true, y_pred, axis=1):\n","    \"\"\"Pearson correlation function implemented in tensorflow.\n","\n","    Parameters\n","    ----------\n","    y_true: tf.Tensor\n","        Ground truth labels. Shape is (batch_size, time_steps, n_features)\n","    y_pred: tf.Tensor\n","        Predicted labels. Shape is (batch_size, time_steps, n_features)\n","    axis: int\n","        Axis along which to compute the pearson correlation. Default is 1.\n","\n","    Returns\n","    -------\n","    tf.Tensor\n","        Pearson correlation.\n","        Shape is (batch_size, 1, n_features) if axis is 1.\n","    \"\"\"\n","    # Compute the mean of the true and predicted values\n","    y_true_mean = tf.reduce_mean(y_true, axis=axis, keepdims=True)\n","    y_pred_mean = tf.reduce_mean(y_pred, axis=axis, keepdims=True)\n","\n","    # Compute the numerator and denominator of the pearson correlation\n","    numerator = tf.reduce_sum(\n","        (y_true - y_true_mean) * (y_pred - y_pred_mean),\n","        axis=axis,\n","        keepdims=True,\n","    )\n","    std_true = tf.reduce_sum(tf.square(y_true - y_true_mean), axis=axis, keepdims=True)\n","    std_pred = tf.reduce_sum(tf.square(y_pred - y_pred_mean), axis=axis, keepdims=True)\n","    denominator = tf.sqrt(std_true * std_pred)\n","\n","    # Compute the pearson correlation\n","    return tf.math.divide_no_nan(numerator, denominator)\n"],"metadata":{"id":"ocpXeJHra892"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear.py\n"],"metadata":{"id":"v1dFv0RMa4IR"}},{"cell_type":"code","source":["\"\"\" This module contains linear backward model\"\"\"\n","import tensorflow as tf\n","\n","# from task2_regression.models.vlaai import pearson_tf\n","\n","\n","@tf.function\n","def pearson_loss_cut(y_true, y_pred, axis=1):\n","    \"\"\"Pearson loss function.\n","\n","    Parameters\n","    ----------\n","    y_true: tf.Tensor\n","        True values. Shape is (batch_size, time_steps, n_features)\n","    y_pred: tf.Tensor\n","        Predicted values. Shape is (batch_size, time_steps, n_features)\n","\n","    Returns\n","    -------\n","    tf.Tensor\n","        Pearson loss.\n","        Shape is (batch_size, 1, n_features)\n","    \"\"\"\n","    return -pearson_tf(y_true[:, : tf.shape(y_pred)[1], :], y_pred, axis=axis)\n","\n","\n","@tf.function\n","def pearson_metric_cut(y_true, y_pred, axis=1):\n","    \"\"\"Pearson metric function.\n","\n","    Parameters\n","    ----------\n","    y_true: tf.Tensor\n","        True values. Shape is (batch_size, time_steps, n_features)\n","    y_pred: tf.Tensor\n","        Predicted values. Shape is (batch_size, time_steps, n_features)\n","\n","    Returns\n","    -------\n","    tf.Tensor\n","        Pearson metric.\n","        Shape is (batch_size, 1, n_features)\n","    \"\"\"\n","    return pearson_tf(y_true[:, : tf.shape(y_pred)[1], :], y_pred, axis=axis)\n","\n","\n","def simple_linear_model(integration_window=32, nb_filters=1, nb_channels=64):\n","    inp = tf.keras.layers.Input(\n","        (\n","            None,\n","            nb_channels,\n","        )\n","    )\n","    out = tf.keras.layers.Conv1D(nb_filters, integration_window)(inp)\n","    model = tf.keras.models.Model(inputs=[inp], outputs=[out])\n","    model.compile(\n","        tf.keras.optimizers.Adam(),\n","        loss=pearson_loss_cut,\n","        metrics=[pearson_metric_cut]\n","    )\n","    return model\n"],"metadata":{"id":"eWRFzdl6a2_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Sample code to generate test labels (reconstructed envelopes) for\n","the regression task. The requested format for submitting the reconstructed envelopes is\n","as follows:\n","for each subject a json file containing a python dictionary in the\n","format of  ==> {'sample_id': reconstructed_envelope, ... }.\n","\"\"\"\n","\n","import os\n","import glob\n","import json\n","import numpy as np\n","# from task2_regression.models.linear import simple_linear_model\n","\n","\n","# Parameters\n","window_length = 60*64  # one minute\n","# Root dataset directory containing test set\n","# Change the path to the downloaded test dataset dir\n","dataset_dir = \"/content/drive/MyDrive/CAPSTONE_626_645_648_651/Data/OpenMIIR/eeg/64_InputChannels/Sub\"+PNUM+'/P' + PNUM + '-formatted.json'\n","# Path to your pretrained model\n","pretrained_model = '/content/drive/MyDrive/CAPSTONE_626_645_648_651/Data/ICASSP_Auditory_Challenge/vlaai_baseline_task2_regression/pretrained_model/vlaai.h5'\n","# Define and load the pretrained model\n","model = vlaai()\n","model.load_weights(pretrained_model)\n","\n","# test_data_path = glob.glob(os.path.join(dataset_dir, '*.json'))\n","print(\"test_data_path: \",dataset_dir)\n","\n","with open(dataset_dir, 'r') as f:\n","  sub_dictionary = json.load(f)\n","\n","\n","\n","# Get test data from subject dictionary\n","id_list, sub_data = zip(*sub_dictionary.items())\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PwMMI-bcYSC","executionInfo":{"status":"ok","timestamp":1694157298451,"user_tz":-330,"elapsed":5169,"user":{"displayName":"JEFFREY S VARGHESE 2572 Batch,PES University","userId":"11726951605376021785"}},"outputId":"1b1e82e0-eed2-42a5-e5e8-22aa54ce407b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test_data_path:  /content/drive/MyDrive/CAPSTONE_626_645_648_651/Data/OpenMIIR/eeg/64_InputChannels/Sub14/P14-formatted.json\n"]}]},{"cell_type":"code","source":["list_3D=[]\n","for key,value in sub_dictionary.items():\n","  # print(len(value), type(value) ,len(value[0]),type(value[0]))\n","  list_3D.append(value)\n","\n","print(len(list_3D), len(list_3D[0]) , len(list_3D[0][0]))\n","array_3D = np.array(list_3D)\n","array_3D.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uRKRCtGqu6cr","executionInfo":{"status":"ok","timestamp":1694157298453,"user_tz":-330,"elapsed":18,"user":{"displayName":"JEFFREY S VARGHESE 2572 Batch,PES University","userId":"11726951605376021785"}},"outputId":"56e01eb5-105c-40b2-e5c3-66e94886a924"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100 618 64\n"]},{"output_type":"execute_result","data":{"text/plain":["(100, 618, 64)"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["\n","# Normalize data\n","data_mean = np.expand_dims(np.mean(array_3D, axis=1), axis=1)\n","data_std = np.expand_dims(np.std(array_3D, axis=1), axis=1)\n","array_3D = (array_3D - data_mean) / data_std\n","\n","predictions = model.predict(array_3D)\n","# Make predictions json-serializable\n","predictions = [np.array(value).tolist() for value in np.squeeze(predictions)]\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7naZnFfnu9b","executionInfo":{"status":"ok","timestamp":1694157322961,"user_tz":-330,"elapsed":24522,"user":{"displayName":"JEFFREY S VARGHESE 2572 Batch,PES University","userId":"11726951605376021785"}},"outputId":"3029a22c-1f59-4ab2-ded8-dbbf80b9d183"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 23s 5s/step\n"]}]},{"cell_type":"code","source":["print(len(predictions), type(predictions) , len(predictions[0]) , type(predictions[0]) ,type(predictions[0][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bg535FXexSIP","executionInfo":{"status":"ok","timestamp":1694157322968,"user_tz":-330,"elapsed":173,"user":{"displayName":"JEFFREY S VARGHESE 2572 Batch,PES University","userId":"11726951605376021785"}},"outputId":"e56aeccd-f174-4f80-9e3a-01cab77a8552"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100 <class 'list'> 618 <class 'list'> <class 'float'>\n"]}]},{"cell_type":"code","source":["# Create dictionary from id_list and predictions\n","sub = dict(zip(id_list, predictions))\n","\n"],"metadata":{"id":"IwWNnGcdwtyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key,value in sub.items():\n","  print(key, len(value))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqvPvu-anNMw","executionInfo":{"status":"ok","timestamp":1694157322987,"user_tz":-330,"elapsed":139,"user":{"displayName":"JEFFREY S VARGHESE 2572 Batch,PES University","userId":"11726951605376021785"}},"outputId":"ce8031fc-bd1c-49fb-97fe-58f92e238276"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["e0_s12_c1 618\n","e1_s12_c2 618\n","e2_s12_c3 618\n","e3_s3_c1 618\n","e4_s3_c2 618\n","e5_s3_c3 618\n","e6_s23_c1 618\n","e7_s23_c2 618\n","e8_s13_c1 618\n","e9_s13_c2 618\n","e10_s13_c3 618\n","e11_s14_c1 618\n","e12_s14_c3 618\n","e13_s11_c1 618\n","e14_s11_c3 618\n","e15_s1_c1 618\n","e16_s1_c2 618\n","e17_s1_c3 618\n","e18_s2_c1 618\n","e19_s2_c2 618\n","e20_s4_c1 618\n","e21_s4_c2 618\n","e22_s21_c1 618\n","e23_s21_c2 618\n","e24_s21_c3 618\n","e25_s22_c1 618\n","e26_s22_c2 618\n","e27_s22_c3 618\n","e28_s24_c1 618\n","e29_s22_c1 618\n","e30_s22_c2 618\n","e31_s22_c3 618\n","e32_s4_c1 618\n","e33_s4_c3 618\n","e34_s11_c1 618\n","e35_s11_c2 618\n","e36_s2_c1 618\n","e37_s2_c2 618\n","e38_s21_c1 618\n","e39_s21_c2 618\n","e40_s13_c1 618\n","e41_s13_c2 618\n","e42_s13_c3 618\n","e43_s3_c1 618\n","e44_s3_c3 618\n","e45_s23_c1 618\n","e46_s23_c3 618\n","e47_s12_c1 618\n","e48_s12_c2 618\n","e49_s12_c3 618\n","e50_s24_c1 618\n","e51_s24_c2 618\n","e52_s1_c1 618\n","e53_s1_c2 618\n","e54_s1_c3 618\n","e55_s14_c1 618\n","e56_s14_c3 618\n","e57_s14_c1 618\n","e58_s22_c1 618\n","e59_s22_c2 618\n","e60_s22_c3 618\n","e61_s23_c1 618\n","e62_s23_c2 618\n","e63_s23_c3 618\n","e64_s12_c1 618\n","e65_s12_c2 618\n","e66_s12_c3 618\n","e67_s21_c1 618\n","e68_s21_c3 618\n","e69_s4_c1 618\n","e70_s4_c3 618\n","e71_s11_c1 618\n","e72_s11_c3 618\n","e73_s1_c1 618\n","e74_s1_c2 618\n","e75_s1_c3 618\n","e76_s13_c1 618\n","e77_s3_c1 618\n","e78_s3_c2 618\n","e79_s3_c3 618\n","e80_s2_c1 618\n","e81_s24_c1 618\n","e82_s24_c2 618\n","e83_s4_c1 618\n","e84_s4_c2 618\n","e85_s21_c1 618\n","e86_s21_c3 618\n","e87_s2_c1 618\n","e88_s2_c2 618\n","e89_s12_c1 618\n","e90_s12_c2 618\n","e91_s12_c3 618\n","e92_s11_c1 618\n","e93_s11_c2 618\n","e94_s11_c3 618\n","e95_s23_c1 618\n","e96_s23_c2 618\n","e97_s22_c1 618\n","e98_s22_c2 618\n","e99_s22_c3 618\n"]}]},{"cell_type":"code","source":["prediction_dir = \"/content/drive/MyDrive/CAPSTONE_626_645_648_651/Data/OpenMIIR/eeg/Testing/64Hz_vlaai_temp/P\" + PNUM + '-predictions.json'\n","# os.makedirs(prediction_dir, exist_ok=True)\n","with open(prediction_dir, 'w') as f:\n","    json.dump(sub, f)"],"metadata":{"id":"JkchZAygxUCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b4L-J1l913YH"},"execution_count":null,"outputs":[]}]}